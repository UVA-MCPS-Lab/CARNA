{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preliminaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import warnings\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load ESCAPE training data\n",
    "escapeAllData = pd.read_csv(\"Data/Original DataFrames/AllDataSingleValue.csv\", sep=\",\", index_col='DEIDNUM') #all feature dataset\n",
    "escapeHemo = pd.read_csv(\"Data/Original DataFrames/HemoSingleValue.csv\", sep=\",\", index_col='DEIDNUM') #dataset with only hemodynamics\n",
    "escapeLabels  = pd.read_csv(\"Data/Original DataFrames/Labels.csv\", sep=\",\", index_col='DEIDNUM') #labels for prediction classes \n",
    "\n",
    "#Load validation\n",
    "aricCohortHemo = pd.read_csv(\"Data Validation/ARIC/Preprocessed Data/Clustered_HemoDF_ARIC_Cohort.csv\", sep=\",\", index_col='ID')\n",
    "aricCohortAllData = pd.read_csv(\"Data Validation/ARIC/Preprocessed Data/Clustered_AllData_ARIC_Cohort.csv\", sep=\",\", index_col='ID')\n",
    "cohortLabels = pd.read_csv(\"Data Validation/ARIC/Original DataFrames/LabelsAricCohort.csv\", sep=\",\", index_col='ID')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cluster Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#HELPER METHODS\n",
    "\n",
    "def plotPCAClusters(X, y_km, K, name): #plot clusters from pca\n",
    "    df = pd.DataFrame(X, columns=[\"Component_1\", \"Component_2\"])\n",
    "    df['Cluster'] = y_km + 1\n",
    "    plt.figure(figsize=(16,7))\n",
    "    sns.scatterplot(x='Component_1', y='Component_2', hue='Cluster', palette=sns.color_palette('hls', K), data=df, legend='full')\n",
    "    plt.title(\"Resulting Score Clusters\")\n",
    "    plt.savefig(\"Score Label Preprocessing/Figures/Score_Clusters_\" + name + \".png\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return X\n",
    "\n",
    "def plotClusters(X, y_km, columns, K): #plot original data clusters\n",
    "    X['cluster'] = y_km\n",
    "    plt.figure(figsize=(16,7))\n",
    "    sns.scatterplot(x=columns[0], y=columns[1], hue='cluster',palette=sns.color_palette('hls', K), data=X, legend='full')\n",
    "    plt.show()\n",
    "    \n",
    "    return X\n",
    "\n",
    "def compareClusters(dt, K): #compare details of clusters\n",
    "    clusters = []\n",
    "    clusterDesc = []\n",
    "    for num in range(K):\n",
    "        cls = dt[dt['cluster'] == num]\n",
    "        clusters.append(cls)\n",
    "\n",
    "#         print(\"Cluster \", num)\n",
    "#         print(cls.describe())\n",
    "        clusterDesc.append(cls.describe())\n",
    "        \n",
    "    return clusters, clusterDesc\n",
    "\n",
    "def runClustering(clusterModel, data, origData, labels, modelName, columns, pca=False):\n",
    "    #Run clustering\n",
    "    y_model = clusterModel.fit_predict(data)\n",
    "\n",
    "    #Save cluster model\n",
    "    pickle.dump(clusterModel, open('Score Label Preprocessing/ClusterModels/' + modelName + '.sav', 'wb'))\n",
    "    \n",
    "    #Plot Clusters\n",
    "    if not pca:\n",
    "        plotClusters(origData, y_model, columns, 5)\n",
    "    else:\n",
    "        plotPCAClusters(data, y_model, 5, modelName)\n",
    "    \n",
    "    #Get real data with clusters\n",
    "    hemoDF = copy.deepcopy(origData)\n",
    "    hemoDF['cluster'] = y_model\n",
    "\n",
    "    #add class labels\n",
    "    hemoDF['Death'] = labels['Death']\n",
    "    hemoDF['Rehosp'] = labels['Rehosp']\n",
    "    hemoDF['Readmission'] = labels['Readmission']\n",
    "\n",
    "    #get descriptions of each cluster\n",
    "    clusters, clusterDesc = compareClusters(hemoDF, 5)\n",
    "    \n",
    "    #get descriptive summary details for each cluster\n",
    "    descSummary = pd.DataFrame()\n",
    "    for i in range(len(clusterDesc)):\n",
    "        descSummary = descSummary.append(clusterDesc[i])\n",
    "    \n",
    "    return hemoDF, descSummary\n",
    "\n",
    "def runValidationClustering(clusterModel, data, origData, labels, columns, pca=False):\n",
    "    #Run clustering\n",
    "    y_model = clusterModel.fit_predict(data) #TODO MIGHT NEED TO CHANGE THIS ONE\n",
    "\n",
    "    #Plot Clusters\n",
    "    if not pca:\n",
    "        plotClusters(origData, y_model, columns, 5)\n",
    "    else:\n",
    "        plotPCAClusters(data, y_model, 5, modelName)\n",
    "    \n",
    "    #Get real data with clusters\n",
    "    hemoDF = copy.deepcopy(origData)\n",
    "    hemoDF['cluster'] = y_model\n",
    "\n",
    "    #add class labels\n",
    "    try:\n",
    "        hemoDF['Death'] = labels['Death']\n",
    "    except:\n",
    "        print(\"No Death Labels\")\n",
    "    try:\n",
    "        hemoDF['Rehosp'] = labels['Rehosp']\n",
    "    except:\n",
    "        print(\"No Rehosp Labels\")\n",
    "    try:\n",
    "        hemoDF['Readmission'] = labels['Readmission']\n",
    "    except:\n",
    "        print(\"No Readmission Labels\")\n",
    "\n",
    "    #get descriptions of each cluster\n",
    "    clusters, clusterDesc = compareClusters(hemoDF, 5)\n",
    "    \n",
    "    #get descriptive summary details for each cluster\n",
    "    descSummary = pd.DataFrame()\n",
    "    for i in range(len(clusterDesc)):\n",
    "        descSummary = descSummary.append(clusterDesc[i])\n",
    "    \n",
    "    return hemoDF, descSummary\n",
    "\n",
    "def assignScoresFromClusters(descSummary):\n",
    "    clsScDF = pd.DataFrame()\n",
    "    clsScDF.index.name = 'Cluster'\n",
    "\n",
    "    scores = [1,2,3,4,5]\n",
    "    dthMn = descSummary.loc['mean']['Death'].to_numpy()\n",
    "    rehospMn = descSummary.loc['mean']['Rehosp'].to_numpy()\n",
    "    readmMn = descSummary.loc['mean']['Readmission'].to_numpy()\n",
    "    \n",
    "    dthScores = [0,0,0,0,0]\n",
    "    cnt = 0\n",
    "    for v in np.argsort(dthMn):\n",
    "        dthScores[v] = scores[cnt]\n",
    "        cnt += 1\n",
    "\n",
    "    rehospScores = [0,0,0,0,0]\n",
    "    cnt = 0\n",
    "    for v in np.argsort(rehospMn):\n",
    "        rehospScores[v] = scores[cnt]\n",
    "        cnt += 1\n",
    "\n",
    "    readmScores = [0,0,0,0,0]\n",
    "    cnt = 0\n",
    "    for v in np.argsort(readmMn):\n",
    "        readmScores[v] = scores[cnt]\n",
    "        cnt += 1\n",
    "\n",
    "    clsScDF['DeathMean'] = dthMn\n",
    "    clsScDF['DeathScores'] = dthScores\n",
    "    clsScDF['RehospMean'] = rehospMn\n",
    "    clsScDF['RehospScores'] = rehospScores\n",
    "    clsScDF['ReadmMean'] = readmMn\n",
    "    clsScDF['ReadmScores'] = readmScores\n",
    "\n",
    "    aveScores = []\n",
    "    for i in clsScDF.index:\n",
    "        c = clsScDF.loc[i]\n",
    "        a = c['DeathScores'] + c['RehospScores'] + c['ReadmScores']\n",
    "        aveScores.append(a/3)\n",
    "\n",
    "    clsScDF['AveScores'] = aveScores\n",
    "    return clsScDF\n",
    "    \n",
    "\n",
    "def saveClusteredData(hemoDF, scoreAsmts, saveName):\n",
    "    \n",
    "    clusNums = hemoDF['cluster']\n",
    "\n",
    "    labels = []\n",
    "    for c in clusNums:\n",
    "        labels.append(int(scoreAsmts.loc[c]['FinalScores']))\n",
    "    hemoDF['Score'] = labels\n",
    "\n",
    "    #Death Scores\n",
    "    labels = []\n",
    "    for c in clusNums:\n",
    "        labels.append(int(scoreAsmts.loc[c]['DeathScores']))\n",
    "    hemoDF['ScoreDeath'] = labels\n",
    "\n",
    "    #Rehosp Scores\n",
    "    labels = []\n",
    "    for c in clusNums:\n",
    "        labels.append(int(scoreAsmts.loc[c]['RehospScores']))\n",
    "\n",
    "    hemoDF['ScoreRehosp'] = labels\n",
    "\n",
    "    #Readm Scores\n",
    "    labels = []\n",
    "    for c in clusNums:\n",
    "        labels.append(int(scoreAsmts.loc[c]['ReadmScores']))\n",
    "    hemoDF['ScoreReadmission'] = labels\n",
    "\n",
    "    hemoDF = hemoDF.drop(columns=[\"cluster\"])\n",
    "    hemoDF = hemoDF.drop(columns=[\"Death\"])\n",
    "    hemoDF = hemoDF.drop(columns=[\"Rehosp\"])\n",
    "    hemoDF = hemoDF.drop(columns=[\"Readmission\"])\n",
    "\n",
    "    hemoDF.to_csv(saveName)\n",
    "    \n",
    "    return hemoDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cluster ESCAPE Hemo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first - try other clustering methods\n",
    "\n",
    "#try clustering to find similar groups using PCA\n",
    "hemo = copy.deepcopy(escapeHemo)\n",
    "hemo = hemo.replace(np.inf, 0)\n",
    "hemo = hemo.fillna(0)\n",
    "data=hemo\n",
    "# scaler = MinMaxScaler()#scale data\n",
    "# hemo.loc[:,:] = scaler.fit_transform(hemo)\n",
    "# pca = PCA(n_components=2)\n",
    "# data = pca.fit_transform(hemo)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO HERE- Choose clustering method\n",
    "ac = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\n",
    "hemoDF, descSummary = runClustering(clusterModel=ac, data=data, origData=escapeHemo, labels=escapeLabels, \n",
    "                                    modelName='AC_Hemo', columns=['MPAP', 'BPDIAS'], pca=False)\n",
    "hemoDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scoreAsmts = assignScoresFromClusters(descSummary)\n",
    "scoreAsmts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO - MUST ALWAYS ADD ASMTS HERE\n",
    "#Note - higher average scores means worse outcomes\n",
    "finalScores = [4, 5, 2, 3, 1]\n",
    "scoreAsmts['FinalScores'] = finalScores\n",
    "scoreAsmts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hemoDF = saveClusteredData(hemoDF, scoreAsmts,\"Data/Preprocessed Data/ESCAPE_AC_Hemo.csv\")\n",
    "hemoDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cluster ARIC Cohort Hemo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Fix labels that only have death\n",
    "cohortLabels['Rehosp']=0\n",
    "cohortLabels['Readmission']=0\n",
    "cohortLabels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hemo = copy.deepcopy(aricCohortHemo)\n",
    "hemo = hemo.replace(np.inf, 0)\n",
    "hemo = hemo.fillna(0)\n",
    "data=hemo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO - update model here\n",
    "model = pickle.load(open('Score Label Preprocessing/ClusterModels/AC_Hemo.sav', 'rb'))\n",
    "hemoDF, descSummary = runValidationClustering(clusterModel=model, data=data, origData=aricCohortHemo, labels=cohortLabels, \n",
    "                                    columns=['MPAP', 'BPDIAS'], pca=False)\n",
    "hemoDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scoreAsmts = assignScoresFromClusters(descSummary)\n",
    "scoreAsmts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO - MUST ALWAYS ADD ASMTS HERE\n",
    "#Note - higher average scores means worse outcomes\n",
    "finalScores = [2,1,4,5,3]\n",
    "scoreAsmts['FinalScores'] = finalScores\n",
    "scoreAsmts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hemoDF = saveClusteredData(hemoDF, scoreAsmts,\"Data Validation/ARIC/Preprocessed Data/ARIC_Cohort_AC_Hemo.csv\")\n",
    "hemoDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "'''\n",
     "HemoPheno4HF\n",
     "SCRIPT DESCRIPTION: Developing Score Labels for Supervised Machine Learning\n",
     "CODE DEVELOPED BY: Josephine Lamp\n",
     "ORGANIZATION: University of Virginia, Charlottesville, VA\n",
     "LAST UPDATED: 8/24/2020\n",
     "'''"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}