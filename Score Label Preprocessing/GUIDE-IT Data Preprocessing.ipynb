{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GUIDE-IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT FILES NEEDED\n",
    "\n",
    "demog = pd.read_csv(\"../Data Validation/GUIDE-IT/Raw Data/demog_ads.csv\", sep=\",\", index_col='deidnum').sort_index()\n",
    "#need to update all these to upload correct files with data needed\n",
    "hfchdxps16 = pd.read_csv(\"../Data Validation/ARIC/Raw Data/cohort/hfchdxps16.csv\", sep=\",\", index_col='ID_S0').sort_index()\n",
    "hfchfaps16 = pd.read_csv(\"../Data Validation/ARIC/Raw Data/cohort/hfchfaps16.csv\", sep=\",\", index_col='ID_S0').sort_index()\n",
    "hfcchips16 = pd.read_csv(\"../Data Validation/ARIC/Raw Data/cohort/hfcchips16.csv\", sep=\",\", index_col='ID_S0').sort_index()\n",
    "hfccfdps16 = pd.read_csv(\"../Data Validation/ARIC/Raw Data/cohort/hfccfdps16.csv\", sep=\",\", index_col='ID_S0').sort_index()\n",
    "hfccelps16 = pd.read_csv(\"../Data Validation/ARIC/Raw Data/cohort/hfccelps16.csv\", sep=\",\", index_col='ID_S0').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Wt_B</th>\n",
       "      <th>Wt_D</th>\n",
       "      <th>BMI_D</th>\n",
       "      <th>EjF</th>\n",
       "      <th>NYHA</th>\n",
       "      <th>TotalHospDays</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S105655</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S105737</th>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>67.7</td>\n",
       "      <td>63.3</td>\n",
       "      <td>28.185923</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S106083</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>36.865164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S106142</th>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79.4</td>\n",
       "      <td>66.8</td>\n",
       "      <td>22.391913</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S106248</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93.3</td>\n",
       "      <td>37.621043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age  Gender  Race  Wt_B  Wt_D      BMI_D   EjF NYHA  TotalHospDays\n",
       "ID                                                                         \n",
       "S105655   76       1     1   NaN   NaN        NaN   NaN  NaN           11.0\n",
       "S105737   76       2     1  67.7  63.3  28.185923  40.0  NaN            3.0\n",
       "S106083   66       2     1  86.0  88.5  36.865164   NaN    0           10.0\n",
       "S106142   77       2     1  79.4  66.8  22.391913  60.0    0           11.0\n",
       "S106248   66       2     1  91.0  93.3  37.621043   NaN  NaN            4.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEMOGRAPHIC\n",
    "\n",
    "cohort = pd.DataFrame()\n",
    "cohort['ID'] = demog.index\n",
    "cohort = cohort.set_index('ID')\n",
    "\n",
    "#continue on from here\n",
    "\n",
    "cohort['Age'] = hfcoccps16['AGE'].tolist()\n",
    "\n",
    "lst = []\n",
    "for idx in hfcoccps16.index:\n",
    "    pt = hfcoccps16.loc[idx]\n",
    "    if pt['SEX'] == 'M': \n",
    "        lst.append(1) #male is 1\n",
    "    else:\n",
    "        lst.append(2) #female 2\n",
    "cohort['Gender'] = lst\n",
    "\n",
    "\n",
    "lst = []\n",
    "for idx in hfcchips16.index:\n",
    "    pt = hfcchips16.loc[idx]\n",
    "    if pt['RACEGRP'] == 'W':#white is 1, all other races are 2\n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(2)\n",
    "cohort['Race'] = lst\n",
    "\n",
    "#weight, convert to all be Kg\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA20A1'] == 'L': #convert lbs to Kg\n",
    "        lst.append(pt['HFAA20A'] * 0.45359237)\n",
    "    else:\n",
    "        lst.append(pt['HFAA20A'])\n",
    "        \n",
    "cohort['Wt_B'] = lst #B = at Baseline\n",
    "\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA20B1'] == 'L': #convert lbs to Kg\n",
    "        lst.append(pt['HFAA20B'] * 0.45359237)\n",
    "    else:\n",
    "        lst.append(pt['HFAA20B'])\n",
    "\n",
    "cohort['Wt_D'] = lst\n",
    "\n",
    "cohort['BMI_D'] = hfcoccps16['BMI'].tolist()\n",
    "cohort['EjF'] = hfcoccps16['LVEF_CUR'].tolist()\n",
    "\n",
    "#NYHA\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA24D'] == 'N': \n",
    "        lst.append(0)\n",
    "    else:\n",
    "        lst.append(pt['HFAA24D']) #number from 1 to 4\n",
    "cohort['NYHA'] = lst\n",
    "\n",
    "allData['InitialHospDays'] = patient['HOSPDAY'] #how many days in first hospitalization\n",
    "cohort['TotalHospDays'] = hfcoccps16['LOS'].tolist() #total length of stay in hospital, cumulative\n",
    "\n",
    "cohort.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#conditions, Ischemic\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA6A'] == 'Y' or pt['HFAA6A'] == 'Y' or pt['HFAA11K'] == 'Y' or  pt['HFAA16J']== 'Y' or  pt['HFAA76']== 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['ISCH'] = lst\n",
    "\n",
    "#Nonischemic\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA6B'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['NonISCH'] = lst\n",
    "\n",
    "#AF\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11B1'] == 'Y' or pt['HFAA16K'] == 'Y' or pt['HFAA26C'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['AF'] = lst\n",
    "\n",
    "#AlchE\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA9B'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['AlchE'] = lst\n",
    "\n",
    "#Angina\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11A'] == 'Y' or pt['HFAA16J'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['ANGP'] = lst\n",
    "\n",
    "#ARRH\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11B1'] == 'Y' or pt['HFAA11B2'] == 'Y' or pt['HFAA11B3'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['ARRH'] = lst\n",
    "\n",
    "#CARREST\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11D'] == 'Y' or pt['HFAA74'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['CARREST'] = lst\n",
    "\n",
    "#COPD\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA10B'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['COPD'] = lst\n",
    "\n",
    "#Depr\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA14B'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['DEPR'] = lst\n",
    "\n",
    "#Diab\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA12A'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['DIAB'] = lst\n",
    "\n",
    "#HEPT\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA22D'] == 'Y' or pt['HFAA22C'] == 'Y' or pt['HFAA12C'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['HEPT'] = lst\n",
    "\n",
    "#HTN\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11J'] == 'Y' or pt['HFAA11L'] == 'Y' or pt['HFAA29D10'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['HTN'] = lst\n",
    "\n",
    "#Malig\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA9E'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['MALIG'] = lst\n",
    "\n",
    "#Malig\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA13A'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['RENAL'] = lst\n",
    "\n",
    "#Smok\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA9H'] == 'Y' or pt['HFAA9G'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['SMOKING'] = lst\n",
    "\n",
    "#Stroke TIA\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA14A'] == 'Y' or pt['HFAA75'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['StrokeTIA'] = lst\n",
    "\n",
    "#VAHD\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11M'] == 'Y' or pt['HFAA28L'] == 'Y' or pt['HFAA28I'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['VAHD'] = lst\n",
    "\n",
    "#VF\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11B3'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['VF'] = lst\n",
    "\n",
    "#VHD\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11O'] == 'Y' or pt['HFAA29D4'] == 'Y' or pt['HFAA29D5'] == 'Y' or pt['HFAA29D6'] == 'Y' or pt['HFAA29D7'] == 'Y' or pt['HFAA29D8'] == 'Y' or pt['HFAA32B4'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['VHD'] = lst\n",
    "\n",
    "#VT\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11B3'] == 'Y' or pt['HFAA26F'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['VT'] = lst\n",
    "\n",
    "#CABG\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11E1'] == 'Y' or pt['HFAA51'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['CABG'] = lst\n",
    "\n",
    "#HTRANS\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA56'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['HTRANS'] = lst\n",
    "\n",
    "#ICD\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11E5'] == 'Y' or pt['HFAA11I'] == 'Y' or pt['HFAA47'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['ICD'] = lst\n",
    "\n",
    "#Pace\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11E4'] == 'Y' or pt['HFAA49'] == 'Y' or pt['HFAA50'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['PACE'] = lst\n",
    "\n",
    "#PTCI\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA11E2'] == 'Y' or pt['HFAA52'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['PTCI'] = lst\n",
    "\n",
    "\n",
    "cohort.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Labs\n",
    "cohort['BUN_D'] = hfchfaps16['HFAA45B'].tolist()\n",
    "cohort['CRT_B'] = hfchfaps16['HFAA44A1'].tolist()\n",
    "\n",
    "#CRT\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if not np.isnan(pt['HFAA44B1']):\n",
    "        lst.append(pt['HFAA44B1'])\n",
    "    else:\n",
    "        lst.append(pt['HFAA44B'])\n",
    "\n",
    "cohort['CRT_D'] = lst\n",
    "cohort['HEC_D'] = hfchfaps16['HFAA38B'].tolist()\n",
    "cohort['HEM_D'] = hfchfaps16['HFAA37B'].tolist()\n",
    "cohort['SOD_D'] = hfchfaps16['HFAA43B'].tolist()\n",
    "\n",
    "#check for other labs here\n",
    "\n",
    "#Check for exercise\n",
    "\n",
    "#Meds\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA59'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['ACE_B'] = lst\n",
    "\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA59A'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['ACE_D'] = lst\n",
    "\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA65'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['BET_B'] = lst\n",
    "\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA65A'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['BET_D'] = lst\n",
    "\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA71'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['NIT_B'] = lst\n",
    "\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA71A'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['NIT_D'] = lst\n",
    "\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA68'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['DIUR_B'] = lst\n",
    "\n",
    "lst = []\n",
    "for idx in hfchfaps16.index:\n",
    "    pt = hfchfaps16.loc[idx]\n",
    "    if pt['HFAA68A'] == 'Y': \n",
    "        lst.append(1)\n",
    "    else:\n",
    "        lst.append(0)\n",
    "cohort['DIUR_D'] = lst\n",
    "\n",
    "cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cohort['HRTRT'] = hfchfaps16['HFAA18A'].tolist()\n",
    "cohort['BPSYS_B'] = hfchfaps16['HFAA17A'].tolist()\n",
    "cohort['BPDIAS_B'] = hfchfaps16['HFAA17B'].tolist()\n",
    "cohort['BPSYS_D'] = hfchfaps16['HFAA17C'].tolist()\n",
    "cohort['BPDIAS_D'] = hfchfaps16['HFAA17D'].tolist()\n",
    "\n",
    "cohort['RAP'] = hfchfaps16['HFAA31B1'].tolist()\n",
    "cohort['PAS'] = hfchfaps16['HFAA31B2'].tolist()\n",
    "cohort['PCWP'] = hfchfaps16['HFAA31B3'].tolist()\n",
    "cohort['CO'] = hfchfaps16['HFAA31B4'].tolist()\n",
    "cohort['CI'] = hfchfaps16['HFAA31B5'].tolist()\n",
    "\n",
    "\n",
    "#Calculate all composite hemo for you --> change data file name to cohort for all these\n",
    "idx = sorted(set(hemoComposite.index))\n",
    "\n",
    "#MAP\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = t['BPSYS_B'] + ((2 * t['BPDIAS_B']) / 3)\n",
    "    f = t['BPSYS_D'] + ((2 * t['BPDIAS_D']) / 3)\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['MAP_B'] = base\n",
    "hemoComposite['MAP_D'] = final\n",
    "hemoComposite['MAP_Chg'] = chg\n",
    "\n",
    "#MPAP\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = t['PAS_B'] + ((2 * t['PAD_B']) / 3)\n",
    "    f = t['PAS_D'] + ((2 * t['PAD_D']) / 3)\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['MPAP_B'] = base\n",
    "hemoComposite['MPAP_D'] = final\n",
    "hemoComposite['MPAP_Chg'] = chg\n",
    "\n",
    "#CPI\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = (t['CI_B'] * t['MAP_B']) / 451\n",
    "    f = (t['CI_D'] * t['MAP_D']) / 451\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['CPI_B'] = base\n",
    "hemoComposite['CPI_D'] = final\n",
    "hemoComposite['CPI_Chg'] = chg\n",
    "    \n",
    "#PP\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = t['BPSYS_B'] - t['BPDIAS_B']\n",
    "    f = t['BPSYS_D'] - t['BPDIAS_D']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['PP_B'] = base\n",
    "hemoComposite['PP_D'] = final\n",
    "hemoComposite['PP_Chg'] = chg\n",
    "\n",
    "#PPP\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = t['PP_B'] / t['BPSYS_B']\n",
    "    f = t['PP_D'] / t['BPSYS_D']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['PPP_B'] = base\n",
    "hemoComposite['PPP_D'] = final\n",
    "hemoComposite['PPP_Chg'] = chg\n",
    "    \n",
    "#PAPP\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = (t['PAS_B']  - t['PAD_B']) / t['PAS_B']\n",
    "    f = (t['PAS_D']  - t['PAD_D']) / t['PAS_D']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['PAPP_B'] = base\n",
    "hemoComposite['PAPP_D'] = final\n",
    "hemoComposite['PAPP_Chg'] = chg\n",
    "\n",
    "#SVR\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = 80 * (t['MAP_B']  - t['RAP_B']) / t['CO_B']\n",
    "    f = 80 * (t['MAP_D']  - t['RAP_D']) / t['CO_D']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['SVR_B'] = base\n",
    "hemoComposite['SVR_D'] = final\n",
    "hemoComposite['SVR_Chg'] = chg\n",
    "\n",
    "#RAT\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = t['RAP_B'] / t['PCWP_B']\n",
    "    f = t['RAP_D'] / t['PCWP_D']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['RAT_B'] = base\n",
    "hemoComposite['RAT_D'] = final\n",
    "hemoComposite['RAT_Chg'] = chg\n",
    "\n",
    "#PPRatio\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = t['PP_B'] / t['HRTRT_B']\n",
    "    f = t['PP_D'] / t['HRTRT_D']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['PPRatio_B'] = base\n",
    "hemoComposite['PPRatio_D'] = final\n",
    "hemoComposite['PPRatio_Chg'] = chg\n",
    "\n",
    "#PAPi\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = (t['PAS_B'] - t['PAD_B']) / t['RAP_B']\n",
    "    f = (t['PAS_D'] - t['PAD_D']) / t['RAP_D']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['PAPi_B'] = base\n",
    "hemoComposite['PAPi_D'] = final\n",
    "hemoComposite['PAPi_Chg'] = chg\n",
    "\n",
    "#SAPi\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = (t['BPSYS_B'] - t['BPDIAS_B']) / t['PCWP_B']\n",
    "    f = (t['BPSYS_D'] - t['BPDIAS_D']) / t['PCWP_D']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['SAPi_B'] = base\n",
    "hemoComposite['SAPi_D'] = final\n",
    "hemoComposite['SAPi_Chg'] = chg\n",
    "\n",
    "#CPP\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = t['BPDIAS_B'] - t['PCWP_B']\n",
    "    f = t['BPDIAS_B'] - t['PCWP_B']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['CPP_B'] = base\n",
    "hemoComposite['CPP_D'] = final\n",
    "hemoComposite['CPP_Chg'] = chg\n",
    "\n",
    "#PRAPRat\n",
    "chg = []\n",
    "base = []\n",
    "final = []\n",
    "for i in idx:\n",
    "    t = hemoComposite.loc[i]\n",
    "\n",
    "    b = t['PP_B'] / t['RAP_B']\n",
    "    f = t['PP_D'] / t['RAP_D']\n",
    "    c = f - b\n",
    "\n",
    "    base.append(b)\n",
    "    final.append(f)\n",
    "    chg.append(c)\n",
    "    \n",
    "hemoComposite['PRAPRat_B'] = base\n",
    "hemoComposite['PRAPRat_D'] = final\n",
    "hemoComposite['PRAPRat_Chg'] = chg\n",
    "\n",
    "hemoComposite.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Make separate datasets --> shouldn't need to change\n",
    "\n",
    "#HEMO\n",
    "varz = ['Age', 'Gender', 'Race', 'EjF', 'RAP', 'PAS', 'PAD', 'PAMN', 'PCWP', 'CO', \n",
    "                            'CI', 'MIXED', 'BPSYS', 'BPDIAS', 'HRTRT', 'MAP','MPAP', 'CPI',\n",
    "                            'PP', 'PPP', 'PAPP', 'SVR', 'RAT', 'PPRatio', 'PAPi', 'SAPi', 'CPP', 'PRAPRat']\n",
    "\n",
    "giantList = []\n",
    "for i in range(len(cohort)):\n",
    "    df = cohort.iloc[i]\n",
    "    row0 = []\n",
    "    row1 = []\n",
    "    row0.append(df.name)\n",
    "    row1.append(df.name)\n",
    "    for col in varz:\n",
    "        if col in cohort.columns: #value for both\n",
    "            row0.append(df[col])\n",
    "            row1.append(df[col])\n",
    "        elif col + \"_B\" in cohort.columns and col + \"_D\" in cohort.columns:\n",
    "            row0.append(df[col+\"_B\"])\n",
    "            row1.append(df[col+\"_D\"])\n",
    "        elif col + \"_B\" in cohort.columns and not col + \"_D\" in cohort.columns:\n",
    "            row0.append(df[col+\"_B\"])\n",
    "            row1.append(0)\n",
    "        elif not col + \"_B\" in cohort.columns and col + \"_D\" in cohort.columns:\n",
    "            row0.append(0)\n",
    "            row1.append(df[col+\"_D\"])\n",
    "        else:\n",
    "            row0.append(0)\n",
    "            row1.append(0)\n",
    "    \n",
    "    giantList.append(row0)\n",
    "    giantList.append(row1)\n",
    "\n",
    "varz.insert(0, 'ID')\n",
    "hemoDF = pd.DataFrame(giantList, columns=varz).set_index('ID', drop=True)\n",
    "    \n",
    "hemoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Get only patients with hemo\n",
    "hemoTest = hemoDF[['RAP', 'PAS', 'PCWP', 'CO', 'CI']]\n",
    "hemoComposite = hemoDF.loc[~(np.isnan(hemoTest)).all(axis=1)]\n",
    "print(hemoComposite.shape)\n",
    "hemoComposite.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#save to file\n",
    "hemoComposite.to_csv(\"../Data Validation/ARIC/Original DataFrames/HemoAricCohort.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAke Hemo Labels\n",
    "labels = pd.DataFrame()\n",
    "labels['ID'] = hemoComposite.index\n",
    "labels = labels.set_index('ID')\n",
    "\n",
    "#Make Labels\n",
    "labels = pd.DataFrame()\n",
    "labels['ID'] = hfcoccps16.index\n",
    "labels = labels.set_index('ID')\n",
    "\n",
    "dthList =  []\n",
    "rhspList = []\n",
    "idx = sorted(set(patient.index))\n",
    "for i in idx:\n",
    "    t = patient.loc[i]\n",
    "    #Death outcome\n",
    "    dth = t[\"DEATH\"] + t['LVADANY'] + t['TRANSP'] #Death is death, LVAD or Transplant \n",
    "    if dth >= 1:\n",
    "        dthList.append(1)\n",
    "    else:\n",
    "        dthList.append(0)\n",
    "        \n",
    "    #Rehosp outcome\n",
    "    rhsp = t['REHOSP'] #Any rehospitalization\n",
    "    if rhsp >= 1:\n",
    "        rhspList.append(1)\n",
    "    else:\n",
    "        rhspList.append(0)\n",
    "        \n",
    "\n",
    "#make readmit labels --> rehospitalization in <= 30 days\n",
    "reAdList = []\n",
    "idx = sorted(set(patient.index))\n",
    "for i in idx:\n",
    "    t = patient.loc[i]\n",
    "    adt = t['T2REHSP']  #days to first rehosp\n",
    "    if adt < 30:\n",
    "        reAdList.append(1)\n",
    "    else:\n",
    "        reAdList.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "labels.to_csv(\"../Data Validation/ARIC/Original DataFrames/HemoLabelsAricCohort.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Make separate datasets\n",
    "\n",
    "#All Data - conditions\n",
    "varz = ['Age', 'Gender', 'Race', 'Wt', 'BMI', \n",
    "       'InitialHospDays', 'TotalHospDays', 'NYHA', 'MLHFS', 'AF',\n",
    "       'AlchE', 'ANGP', 'ARRH', 'CARREST', 'CVD', 'COPD', 'DEPR', 'DIAB',\n",
    "       'GOUT', 'HEPT', 'HTN', 'MALIG', 'RENAL', 'SMOKING', 'STERD',\n",
    "       'StrokeTIA', 'VAHD', 'VF', 'VHD', 'VT', 'ISCH', 'NonISCH', 'CABG',\n",
    "       'HTRANS', 'ICD', 'PACE', 'PTCI', 'SixFtWlk', 'VO2','ALB', 'ALT', 'AST', 'BUN',\n",
    "       'CRT', 'DIAL', 'HEC', \n",
    "       'HEM','PLA', 'POT',  'SOD',\n",
    "       'TALB', 'TOTP', 'WBC', 'ACE','BET', 'NIT', 'DIUR',\n",
    "       'EjF', 'BPDIAS', 'BPSYS', 'HR',\n",
    "       'PV', 'MAP', 'PP', 'PPP', 'PPRatio']\n",
    "\n",
    "\n",
    "\n",
    "giantList = []\n",
    "for i in range(len(cohort)):\n",
    "    df = cohort.iloc[i]\n",
    "    row0 = []\n",
    "    row1 = []\n",
    "    row0.append(df.name)\n",
    "    row1.append(df.name)\n",
    "    for col in varz:\n",
    "        if col in cohort.columns: #value for both\n",
    "            row0.append(df[col])\n",
    "            row1.append(df[col])\n",
    "        elif col + \"_B\" in cohort.columns and col + \"_D\" in cohort.columns:\n",
    "            row0.append(df[col+\"_B\"])\n",
    "            row1.append(df[col+\"_D\"])\n",
    "        elif col + \"_B\" in cohort.columns and not col + \"_D\" in cohort.columns:\n",
    "            row0.append(df[col+\"_B\"])\n",
    "            row1.append(0)\n",
    "        elif not col + \"_B\" in cohort.columns and col + \"_D\" in cohort.columns:\n",
    "            row0.append(0)\n",
    "            row1.append(df[col+\"_D\"])\n",
    "        else:\n",
    "            row0.append(0)\n",
    "            row1.append(0)\n",
    "    \n",
    "    giantList.append(row0)\n",
    "    giantList.append(row1)\n",
    "\n",
    "varz.insert(0, 'ID')\n",
    "allData = pd.DataFrame(giantList, columns=varz).set_index('ID', drop=True)\n",
    "    \n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#save to file\n",
    "allData.to_csv(\"../Data Validation/ARIC/Original DataFrames/AllDataAricCohort.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Make Labels\n",
    "labels = pd.DataFrame()\n",
    "labels['ID'] = hfcoccps16.index\n",
    "labels = labels.set_index('ID')\n",
    "\n",
    "dthList =  []\n",
    "rhspList = []\n",
    "idx = sorted(set(patient.index))\n",
    "for i in idx:\n",
    "    t = patient.loc[i]\n",
    "    #Death outcome\n",
    "    dth = t[\"DEATH\"] + t['LVADANY'] + t['TRANSP'] #Death is death, LVAD or Transplant \n",
    "    if dth >= 1:\n",
    "        dthList.append(1)\n",
    "    else:\n",
    "        dthList.append(0)\n",
    "        \n",
    "    #Rehosp outcome\n",
    "    rhsp = t['REHOSP'] #Any rehospitalization\n",
    "    if rhsp >= 1:\n",
    "        rhspList.append(1)\n",
    "    else:\n",
    "        rhspList.append(0)\n",
    "        \n",
    "\n",
    "#make readmit labels --> rehospitalization in <= 30 days\n",
    "reAdList = []\n",
    "idx = sorted(set(patient.index))\n",
    "for i in idx:\n",
    "    t = patient.loc[i]\n",
    "    adt = t['T2REHSP']  #days to first rehosp\n",
    "    if adt < 30:\n",
    "        reAdList.append(1)\n",
    "    else:\n",
    "        reAdList.append(0)\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "labels.to_csv(\"../Data Validation/ARIC/Original DataFrames/LabelsAricCohort.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}